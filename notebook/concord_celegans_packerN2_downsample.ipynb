{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concord as ccd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from pathlib import Path\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = \"cel_packerN2_downsample\"\n",
    "file_name = \"cel_packerN2_downsample\"\n",
    "file_suffix = time.strftime('%b%d-%H%M')\n",
    "seed = 0\n",
    "ccd.ul.set_seed(seed)\n",
    "save_dir = Path(f\"../save/{proj_name}\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = Path(f\"../data/{proj_name}\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(Path('../data/CBCEcombineN2/') / 'adata_celsub_Jun26-1610.h5ad')\n",
    "sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=10000, subset=False)\n",
    "sc.tl.pca(adata, n_comps=300, svd_solver='arpack', use_highly_variable=True)\n",
    "adata = adata[:, adata.var.highly_variable].copy()\n",
    "adata.write_h5ad(data_dir / f\"{file_name}_preprocessed.h5ad\")\n",
    "print(f\"‚úÖ Preprocessed data saved to {data_dir / f'{file_name}_preprocessed.h5ad'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE     = Path(f\"{file_name}_preprocessed.h5ad\")\n",
    "adata = sc.read_h5ad(data_dir / DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "fractions = [1.0, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "concord_args = {\n",
    "    \"latent_dim\": 300,\n",
    "    \"batch_size\": 256,\n",
    "    \"encoder_dims\": [1000],\n",
    "    \"p_intra_domain\": 1.0,\n",
    "    \"augmentation_mask_prob\": 0.30,\n",
    "    \"clr_temperature\": 0.30,\n",
    "    \"sampler_knn\": 1000,\n",
    "    \"n_epochs\": 15,        # gets overwritten below\n",
    "    \"lr\":       1e-2,   # gets overwritten below\n",
    "}\n",
    "\n",
    "py_methods = [\"scvi\", \"harmony\", \"scanorama\", \"liger\", \"unintegrated\", \"concord_hcl\", \"concord_knn\", \"contrastive\"]\n",
    "output_dir = '../jobs'\n",
    "device = 'auto'\n",
    "conda_env = 'concord'\n",
    "batch_key = 'batch'\n",
    "state_key = 'None'\n",
    "latent_dim = '300'  # Adjust as needed, but should match the encoder_dims in concord_args\n",
    "\n",
    "\n",
    "for frac in fractions:\n",
    "    adata_name = f\"{file_name}_downsampled_{int(frac * 100)}.h5ad\"\n",
    "    tag        = f\"ds{int(frac * 100)}\"                   # keeps job names unique\n",
    "    cur_proj = f\"{proj_name}_{tag}\"\n",
    "    cur_dir = Path(\"../data\") / cur_proj\n",
    "    cur_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if frac < 1.0:\n",
    "        downsampled_adata = adata.copy()\n",
    "        n_cells = int(len(downsampled_adata) * frac)\n",
    "        print(f\"Downsampling to {frac * 100:.1f}% of the original data ({n_cells} cells)\")\n",
    "        downsampled_adata = downsampled_adata[:n_cells, :].copy()\n",
    "        downsampled_adata.obs['downsample_fraction'] = frac\n",
    "        downsampled_adata.write_h5ad(cur_dir / f\"{file_name}_downsampled_{int(frac * 100)}.h5ad\")\n",
    "        print(f\"‚úÖ Downsampled data saved to {cur_dir / f'{file_name}_downsampled_{int(frac * 100)}.h5ad'}\")\n",
    "    else:\n",
    "        downsampled_adata = adata.copy()\n",
    "        downsampled_adata.write_h5ad(cur_dir / f\"{file_name}_downsampled_{int(frac * 100)}.h5ad\")\n",
    "\n",
    "    subprocess.run([\n",
    "        \"python\", \"./generate_py_jobs.py\",\n",
    "        \"--proj_name\", f\"{proj_name}_{tag}\",\n",
    "        \"--adata_filename\", adata_name,\n",
    "        \"--methods\", *py_methods,\n",
    "        \"--batch_key\", batch_key,\n",
    "        \"--state_key\", state_key,\n",
    "        \"--latent_dim\", latent_dim,\n",
    "        \"--output_dir\", output_dir,\n",
    "        \"--device\", device,\n",
    "        \"--conda_env\", conda_env,\n",
    "        \"--runtime\", \"02:00:00\",\n",
    "        \"--concord_kwargs\", json.dumps(concord_args),\n",
    "        \"--root_save_dir\", \"../save\",\n",
    "        \"--root_data_dir\", \"../data\",\n",
    "    ], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# create submit_sequential_<proj>.sh  (runs each *.py job in order)\n",
    "# ------------------------------------------------------------------\n",
    "sequential_submit = Path(\"../jobs\") / f\"submit_sequential_{proj_name}.sh\"\n",
    "\n",
    "# NOTE: only the for-loop glob changed ‚Üì‚Üì‚Üì\n",
    "sequential_template = f\"\"\"#!/usr/bin/env bash\n",
    "set -euo pipefail\n",
    "cd \"$(dirname \"$0\")\"            # work inside this folder (../jobs)\n",
    "shopt -s nullglob\n",
    "\n",
    "for folder in benchmark_{proj_name}_*; do\n",
    "  [[ -d \"$folder\" ]] || continue\n",
    "  echo \"===== entering $folder  $(date) =====\"\n",
    "\n",
    "  for job in \"$folder\"/*.py; do\n",
    "    [[ -e \"$job\" ]] || continue\n",
    "\n",
    "    base=${{job%.py}}\n",
    "    log=\"${{base}}.log\"\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # skip if a previous run finished successfully\n",
    "    #   ‚Ä¢ If you only care that the log exists (no success check),\n",
    "    #     drop the grep clause.\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if [[ -f \"$log\" ]] && grep -q \"finished OK\" \"$log\"; then\n",
    "        echo \">>> SKIP $job  ‚Äî already completed\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    echo \">>> $job   $(date)\" | tee -a \"$log\"\n",
    "    if python \"$job\" >>\"$log\" 2>&1; then\n",
    "        echo \">>> finished OK\" | tee -a \"$log\"\n",
    "    else\n",
    "        echo \">>> FAILED\"      | tee -a \"$log\"\n",
    "    fi\n",
    "  done\n",
    "done\n",
    "\"\"\"\n",
    "\n",
    "sequential_submit.write_text(sequential_template)\n",
    "sequential_submit.chmod(0o755)\n",
    "print(f\"üìå  Run ‚Äú{sequential_submit}‚Äù to queue the down-sample benchmarks sequentially.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_utils import add_embeddings\n",
    "methods = [\"scvi\", \"harmony\", \"scanorama\", \"liger\", \"unintegrated\", \"concord_hcl\", \"concord_knn\", \"contrastive\"]\n",
    "fractions = [1.0, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "\n",
    "for frac in fractions:\n",
    "    adata_name = f\"{file_name}_downsampled_{int(frac * 100)}.h5ad\"\n",
    "    tag        = f\"ds{int(frac * 100)}\"                   # keeps job names unique\n",
    "    cur_proj = f\"{proj_name}_{tag}\"\n",
    "    cur_dir = Path(\"../data\") / cur_proj\n",
    "    cur_adata = sc.read_h5ad(cur_dir / adata_name)\n",
    "    print(f\"Running benchmarks for {cur_proj} with {len(cur_adata)} cells and {len(cur_adata.var)} genes.\")\n",
    "    cur_adata = add_embeddings(cur_adata, proj_name=cur_proj, methods=methods)\n",
    "    cur_adata.write_h5ad(cur_dir / f\"{file_name}_downsampled_{int(frac * 100)}_final.h5ad\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_utils import collect_benchmark_logs\n",
    "\n",
    "for frac in fractions:\n",
    "    adata_name = f\"{file_name}_downsampled_{int(frac * 100)}.h5ad\"\n",
    "    tag        = f\"ds{int(frac * 100)}\"                   # keeps job names unique\n",
    "    cur_proj = f\"{proj_name}_{tag}\"\n",
    "    bench_df = collect_benchmark_logs(cur_proj, methods)\n",
    "    # Save the benchmark results\n",
    "    bench_df.to_csv(save_dir / f\"{cur_proj}_benchmark_summary_{file_suffix}.tsv\", sep=\"\\t\", index=False)\n",
    "    print(f\"‚úÖ Benchmark summary saved to: {save_dir / f'{cur_proj}_benchmark_summary_{file_suffix}.tsv'}\")\n",
    "    # Plot benchmark results\n",
    "    from benchmark_utils import plot_benchmark_performance\n",
    "    import matplotlib.pyplot as plt\n",
    "    custom_rc = {\n",
    "        'font.family': 'Arial',  # Set the desired font for this plot\n",
    "    }\n",
    "    with plt.rc_context(rc=custom_rc):\n",
    "        plot_benchmark_performance(bench_df, figsize=(8,2), dpi=300, save_path = save_dir / f\"{cur_proj}_benchmark_plot_{file_suffix}.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ct.obs['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bad_annotation = [np.nan, '', 'unknown', 'None', 'nan', 'NaN', 'NA', 'na', 'unannotated']\n",
    "\n",
    "state_benchmarks = {}\n",
    "for frac in fractions:  # reverse order to process larger fractions first\n",
    "    adata_name = f\"{file_name}_downsampled_{int(frac * 100)}_final.h5ad\"\n",
    "    tag        = f\"ds{int(frac * 100)}\"                   # keeps job names unique\n",
    "    cur_proj = f\"{proj_name}_{tag}\"\n",
    "    cur_dir = Path(\"../data\") / cur_proj\n",
    "    cur_adata = sc.read_h5ad(cur_dir / adata_name)\n",
    "    bad_cells = cur_adata.obs['cell_type'].isin(bad_annotation)\n",
    "    # Also remove cells with classes with less than 2 cells\n",
    "    # cell_counts = cur_adata.obs['cell_type'].value_counts()\n",
    "    # bad_cells |= cur_adata.obs['cell_type'].isin(cell_counts[cell_counts < 3].index)\n",
    "\n",
    "    print(f\"Filtering {cur_proj} to remove bad annotations: {bad_cells.sum()} cells out of {len(cur_adata)}\")\n",
    "    adata_ct = cur_adata[~bad_cells].copy()\n",
    "\n",
    "    print(f\"‚úÖ Filtered adata to remove bad annotations, new shape: {adata_ct.shape}\")\n",
    "    state_counts = len(adata_ct.obs['cell_type'].value_counts())\n",
    "    batch_counts = len(adata_ct.obs['batch'].value_counts())\n",
    "    print(f\"Cell types: {state_counts}, Batches: {batch_counts}\")\n",
    "    state_key = 'cell_type' if state_counts > 1 else None\n",
    "    batch_key = 'batch' if batch_counts > 1 else None\n",
    "    out = ccd.bm.run_benchmark_pipeline(\n",
    "        adata_ct,\n",
    "        embedding_keys=methods,\n",
    "        state_key=state_key,\n",
    "        batch_key=batch_key,\n",
    "        save_dir=save_dir / f\"{cur_proj}_benchmarks_{state_key}\",\n",
    "        file_suffix=file_suffix,  # e.g. \"2025-06-25\"\n",
    "        run=(\"probe\"),          # run only these blocks\n",
    "        plot_individual=False,          # skip the intermediate PDFs\n",
    "    )\n",
    "    combined_celltype = out[\"combined\"]\n",
    "    state_benchmarks[tag] = combined_celltype\n",
    "\n",
    "    # Save the benchmark results\n",
    "    import pickle\n",
    "    with open(save_dir / f\"{cur_proj}_benchmark_{state_key}_{file_suffix}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(out, f)\n",
    "    print(f\"‚úÖ Benchmark results saved to: {save_dir / f'{cur_proj}_benchmark_{state_key}_{file_suffix}.pkl'}\")\n",
    "\n",
    "with open(save_dir / f\"{proj_name}_{state_key}_benchmarks_{file_suffix}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(state_benchmarks, f)\n",
    "print(f\"‚úÖ State benchmarks saved to: {save_dir / f'{proj_name}_{state_key}_benchmarks_{file_suffix}.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bad_annotation = [np.nan, '', 'unknown', 'None', 'nan', 'NaN', 'NA', 'na', 'unannotated']\n",
    "\n",
    "state_benchmarks = {}\n",
    "for frac in fractions:  # reverse order to process larger fractions first\n",
    "    adata_name = f\"{file_name}_downsampled_{int(frac * 100)}_final.h5ad\"\n",
    "    tag        = f\"ds{int(frac * 100)}\"                   # keeps job names unique\n",
    "    cur_proj = f\"{proj_name}_{tag}\"\n",
    "    cur_dir = Path(\"../data\") / cur_proj\n",
    "    cur_adata = sc.read_h5ad(cur_dir / adata_name)\n",
    "    bad_cells = cur_adata.obs['lineage_complete'].isin(bad_annotation)\n",
    "\n",
    "    print(f\"Filtering {cur_proj} to remove bad annotations: {bad_cells.sum()} cells out of {len(cur_adata)}\")\n",
    "    adata_ct = cur_adata[~bad_cells].copy()\n",
    "\n",
    "    print(f\"‚úÖ Filtered adata to remove bad annotations, new shape: {adata_ct.shape}\")\n",
    "    state_counts = len(adata_ct.obs['lineage_complete'].value_counts())\n",
    "    batch_counts = len(adata_ct.obs['batch'].value_counts())\n",
    "    print(f\"Cell types: {state_counts}, Batches: {batch_counts}\")\n",
    "    state_key = 'lineage_complete' if state_counts > 1 else None\n",
    "    batch_key = 'batch' if batch_counts > 1 else None\n",
    "    out = ccd.bm.run_benchmark_pipeline(\n",
    "        adata_ct,\n",
    "        embedding_keys=methods,\n",
    "        state_key=state_key,\n",
    "        batch_key=batch_key,\n",
    "        save_dir=save_dir / f\"{cur_proj}_benchmarks_{state_key}\",\n",
    "        file_suffix=file_suffix,  # e.g. \"2025-06-25\"\n",
    "        run=(\"probe\"),          # run only these blocks\n",
    "        plot_individual=False,          # skip the intermediate PDFs\n",
    "    )\n",
    "    combined_celltype = out[\"combined\"]\n",
    "    state_benchmarks[tag] = combined_celltype\n",
    "\n",
    "    # Save the benchmark results\n",
    "    import pickle\n",
    "    with open(save_dir / f\"{cur_proj}_benchmark_{state_key}_{file_suffix}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(out, f)\n",
    "    print(f\"‚úÖ Benchmark results saved to: {save_dir / f'{cur_proj}_benchmark_{state_key}_{file_suffix}.pkl'}\")\n",
    "\n",
    "with open(save_dir / f\"{proj_name}_{state_key}_benchmarks_{file_suffix}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(state_benchmarks, f)\n",
    "print(f\"‚úÖ State benchmarks saved to: {save_dir / f'{proj_name}_{state_key}_benchmarks_{file_suffix}.pkl'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concord",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
