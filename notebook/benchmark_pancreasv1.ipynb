{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concord as ccd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from pathlib import Path\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "proj_name = \"pancreasv1_5k\"\n",
    "file_name = proj_name\n",
    "file_suffix = time.strftime('%b%d-%H%M')\n",
    "seed = 0\n",
    "\n",
    "save_dir = Path(f\"../save/{proj_name}\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = Path(f\"../data/{proj_name}\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\n",
    "    data_dir / \"dataset.h5ad\"\n",
    ")\n",
    "adata.X = adata.layers[\"counts\"].copy()\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3', subset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[:, adata.var.highly_variable].copy()\n",
    "adata.write_h5ad(data_dir / f\"{file_name}_preprocessed_HVG.h5ad\")\n",
    "print(f\"‚úÖ Preprocessed data saved to {data_dir / f'{file_name}_preprocessed_HVG.h5ad'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(data_dir / f\"{file_name}_preprocessed_HVG.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concord_args = {\n",
    "        'batch_size': 64\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, json\n",
    "py_methods = [\"scvi\", \"harmony\", \"scanorama\", \"liger\", \"unintegrated\", \"concord_hcl\", \"concord_knn\", \"contrastive\"]\n",
    "py_methods = [\"scvi\", \"concord_hcl\", \"concord_knn\", \"contrastive\", \"harmony\"]\n",
    "py_methods = [\"concord_hcl\", \"concord_knn\", \"contrastive\"]\n",
    "output_dir = '../jobs'\n",
    "device = 'auto'\n",
    "#conda_env = 'cellpath'\n",
    "conda_env='concord'\n",
    "batch_key = \"batch\"\n",
    "state_key = 'None'\n",
    "latent_dim = '50'  # Adjust as needed, but should match the encoder_dims in concord_args\n",
    "subprocess.run([\n",
    "    \"python\", \"./generate_py_jobs.py\",\n",
    "    \"--proj_name\", proj_name,\n",
    "    \"--adata_filename\", f\"{file_name}_preprocessed_HVG.h5ad\",\n",
    "    \"--methods\", *py_methods,\n",
    "    \"--batch_key\", batch_key,\n",
    "    \"--state_key\", state_key,\n",
    "    \"--latent_dim\", latent_dim,\n",
    "    \"--output_dir\", output_dir,\n",
    "    \"--device\", device,\n",
    "    \"--mem\", \"32G\",  # Adjust memory as needed\n",
    "    \"--conda_env\", conda_env,\n",
    "    \"--runtime\", \"1:30:00\",\n",
    "    \"--mode\", \"wynton\",\n",
    "    \"--concord_kwargs\", json.dumps(concord_args)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd.ul.anndata_to_viscello(adata,\n",
    "                        output_dir=data_dir / f\"viscello_{proj_name}\",\n",
    "                        project_name=proj_name,\n",
    "                        organism='mmu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate script for Seurat\n",
    "import subprocess\n",
    "r_methods = [\"seurat_cca\", \"seurat_rpca\"]\n",
    "output_dir = '../jobs'\n",
    "device = 'auto'\n",
    "subprocess.run([\n",
    "    \"python\", \"./generate_seurat_script.py\",\n",
    "    \"--proj_name\", proj_name,\n",
    "    \"--eset_dir\", '../'+ str(data_dir / f\"viscello_{proj_name}\"),   # <- folder w/ eset.rds\n",
    "    \"--methods\", *r_methods,\n",
    "    \"--batch_key\", batch_key,\n",
    "    \"--state_key\", state_key,\n",
    "    \"--latent_dim\", latent_dim,\n",
    "    \"--mem\", \"80G\",  # Adjust memory as needed\n",
    "    \"--runtime\", \"12:00:00\",\n",
    "    \"--output_dir\", output_dir,\n",
    "    \"--device\", device,\n",
    "    \"--conda_env\", conda_env\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_folder = Path(output_dir) / f\"benchmark_{proj_name}\"   # ../jobs/benchmark_<proj>\n",
    "proj_folder.mkdir(exist_ok=True)                      # defensive\n",
    "\n",
    "submit_all = proj_folder / f\"submit_all_{proj_name}.sh\"\n",
    "with submit_all.open(\"w\") as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    f.write(\"# Auto-generated ‚Äî submits every job for this project\\n\")\n",
    "    f.write(\"# Run from this folder, or let the script cd into it.\\n\\n\")\n",
    "    f.write('cd \"$(dirname \"$0\")\"\\n\\n')          # ensures we‚Äôre in the right dir\n",
    "    for sh_file in sorted(proj_folder.glob(f\"benchmark_{proj_name}_*.sh\")):\n",
    "        f.write(f'qsub \"{sh_file.name}\"\\n')\n",
    "\n",
    "submit_all.chmod(0o755)\n",
    "print(f\"üìå  Run ‚Äú{submit_all}‚Äù to queue every job.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# create submit_sequential_<proj>.sh  (runs each *.py job in order)\n",
    "# ------------------------------------------------------------------\n",
    "sequential_submit = proj_folder / f\"submit_sequential_{proj_name}.sh\"\n",
    "\n",
    "sequential_template = f\"\"\"#!/usr/bin/env bash\n",
    "set -euo pipefail\n",
    "cd \"$(dirname \"$0\")\"            # work inside this folder (../jobs)\n",
    "shopt -s nullglob\n",
    "\n",
    "for job in benchmark_{proj_name}_*.py; do\n",
    "  base=${{job%.py}}\n",
    "  log=\"${{base}}.log\"\n",
    "\n",
    "  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  # skip if a previous run finished successfully\n",
    "  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  if [[ -f \"$log\" ]] && grep -q \"finished OK\" \"$log\"; then\n",
    "      echo \">>> SKIP $job  ‚Äî already completed\"\n",
    "      continue\n",
    "  fi\n",
    "\n",
    "  echo \">>> $job   $(date)\" | tee -a \"$log\"\n",
    "  if python \"$job\" >>\"$log\" 2>&1; then\n",
    "      echo \">>> finished OK\" | tee -a \"$log\"\n",
    "  else\n",
    "      echo \">>> FAILED\"      | tee -a \"$log\"\n",
    "  fi\n",
    "done\n",
    "\"\"\"\n",
    "\n",
    "sequential_submit.write_text(sequential_template)\n",
    "sequential_submit.chmod(0o755)\n",
    "print(f\"üìå  Run ‚Äú{sequential_submit}‚Äù to queue jobs sequentially.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Benchmark summary saved to: ../save/pancreasv1_5k/benchmark_summary_Aug09-1655.tsv\n"
     ]
    }
   ],
   "source": [
    "from benchmark_utils import collect_benchmark_logs\n",
    "methods = [\"scvi\", \"harmony\", \"scanorama\", \"liger\", \"unintegrated\", \"concord_hcl\", \"concord_knn\", \"contrastive\", \"seurat_cca\", \"seurat_rpca\"]\n",
    "\n",
    "bench_df = collect_benchmark_logs(file_name, methods)\n",
    "# Save the benchmark results\n",
    "bench_df.to_csv(save_dir / f\"benchmark_summary_{file_suffix}.tsv\", sep=\"\\t\", index=False)\n",
    "print(f\"‚úÖ Benchmark summary saved to: {save_dir / f'benchmark_summary_{file_suffix}.tsv'}\")\n",
    "# Plot benchmark results\n",
    "from benchmark_utils import plot_benchmark_performance\n",
    "import matplotlib.pyplot as plt\n",
    "custom_rc = {\n",
    "    'font.family': 'Arial',  # Set the desired font for this plot\n",
    "}\n",
    "with plt.rc_context(rc=custom_rc):\n",
    "    plot_benchmark_performance(bench_df, figsize=(8,2), dpi=300, save_path = save_dir / f\"benchmark_plot_{file_suffix}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\n",
    "    data_dir / \"dataset.h5ad\"\n",
    ")\n",
    "adata.X = adata.layers[\"counts\"].copy()\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ obsm['scvi'] loaded\n",
      "‚úÖ obsm['harmony'] loaded\n",
      "‚úÖ obsm['scanorama'] loaded\n",
      "‚úÖ obsm['liger'] loaded\n",
      "‚úÖ obsm['unintegrated'] loaded\n",
      "‚úÖ obsm['concord_hcl'] loaded\n",
      "‚úÖ obsm['concord_knn'] loaded\n",
      "‚úÖ obsm['contrastive'] loaded\n",
      "‚úÖ obsm['seurat_cca'] loaded\n",
      "‚úÖ obsm['seurat_rpca'] loaded\n"
     ]
    }
   ],
   "source": [
    "from benchmark_utils import add_embeddings\n",
    "adata = add_embeddings(adata, proj_name=proj_name, methods=methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run umap for all latent embeddings\n",
    "for basis in methods:\n",
    "    print(\"Running UMAP for\", basis)\n",
    "    if basis not in adata.obsm:\n",
    "        print(f\"{basis} not found.\")\n",
    "        continue\n",
    "    #if 'UMAP' not in basis:\n",
    "    ccd.ul.run_umap(adata, source_key=basis, result_key=f'{basis}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\n",
    "    #ccd.ul.run_umap(adata, source_key=basis, result_key=f'{basis}_UMAP_3D', n_components=3, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\n",
    "\n",
    "# Save obsm \n",
    "ccd.ul.save_obsm_to_hdf5(adata, save_dir / f\"{file_name}_obsm_final.h5\")\n",
    "adata.write_h5ad(data_dir / f\"{file_name}_adata_final.h5ad\")\n",
    "print(f\"‚úÖ Saved adata with embeddings to {data_dir / f'{file_name}_adata_final.h5ad'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot everything\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set Arial as the default font\n",
    "custom_rc = {\n",
    "    'font.family': 'Arial',  # Set the desired font for this plot\n",
    "}\n",
    "\n",
    "show_keys = methods\n",
    "show_cols = ['tech', 'celltype', 'batch']\n",
    "basis_types = ['UMAP']\n",
    "\n",
    "font_size=10\n",
    "point_size=.5\n",
    "alpha=0.8\n",
    "ncols = len(show_keys)\n",
    "figsize=(ncols * 1.5,1.5)\n",
    "nrows = int(np.ceil(len(show_keys) / ncols))\n",
    "\n",
    "with plt.rc_context(rc=custom_rc):\n",
    "    ccd.pl.plot_all_embeddings(\n",
    "        adata,\n",
    "        show_keys,\n",
    "        color_bys=show_cols,\n",
    "        basis_types=basis_types,\n",
    "        #pal=pal,\n",
    "        font_size=font_size,\n",
    "        point_size=point_size,\n",
    "        alpha=alpha,\n",
    "        figsize=figsize,\n",
    "        ncols=ncols,\n",
    "        seed=seed,\n",
    "        save_dir=save_dir,\n",
    "        file_suffix=file_suffix,\n",
    "        dpi=600,\n",
    "        save_format='svg'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = 'concord_hcl'\n",
    "show_basis = basis + '_UMAP'\n",
    "ccd.pl.plot_embedding(\n",
    "    adata, show_basis, show_cols, figsize=(13,5), dpi=600, ncols=3, font_size=10, point_size=3, legend_loc=\"on data\",\n",
    "    save_path=save_dir / f\"{show_basis}_{file_suffix}.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe only version\n",
    "state_key = 'cell_type'\n",
    "batch_key = 'batch'\n",
    "out = ccd.bm.run_benchmark_pipeline(\n",
    "    adata,\n",
    "    embedding_keys=methods,\n",
    "    state_key=state_key,\n",
    "    batch_key=batch_key,\n",
    "    save_dir=save_dir / \"benchmarks_celltype_probe\",\n",
    "    file_suffix=file_suffix,  # e.g. \"2025-06-25\"\n",
    "    run=(\"scib\", \"probe\"),          # run only these blocks\n",
    "    plot_individual=False,          # skip the intermediate PDFs\n",
    ")\n",
    "combined_celltype = out[\"combined\"]\n",
    "\n",
    "# Save the benchmark results\n",
    "import pickle\n",
    "with open(save_dir / f\"benchmark_{state_key}_{file_suffix}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(out, f)\n",
    "\n",
    "print(f\"‚úÖ Benchmark results saved to: {save_dir / f'benchmark_{state_key}_{file_suffix}.pkl'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load if needed\n",
    "import pickle\n",
    "with open(save_dir / f\"benchmark_cell_type_Aug09-1655.pkl\", \"rb\") as f:\n",
    "    out = pickle.load(f)\n",
    "table_plot_kw = dict(\n",
    "        pal=\"viridis\", pal_agg=\"viridis\", cmap_method=\"minmax\", dpi=300)\n",
    "with plt.rc_context(rc=custom_rc):\n",
    "    combined_df = ccd.bm.combine_benchmark_results(\n",
    "        out,\n",
    "        block_include=(\"scib\", \"probe\"),\n",
    "        plot=False,\n",
    "        save_path=save_dir / f\"combined_res_{file_suffix}.pdf\",\n",
    "        table_plot_kw=table_plot_kw,\n",
    "    )\n",
    "    combined_df = combined_df[combined_df.index != \"contrastive\"]\n",
    "    ccd.bm.plot_benchmark_table(\n",
    "            combined_df.dropna(axis=0, how='any'),\n",
    "            save_path=save_dir / f\"benchmark_celltype_{file_suffix}.svg\",\n",
    "            agg_name=\"Aggregate score\",\n",
    "            figsize=(13, 5),\n",
    "            **table_plot_kw\n",
    "            )\n",
    "\n",
    "    # drop method \"contrastive\"\n",
    "    combined_df.index.name = \"Method\"\n",
    "    combined_df.to_csv(save_dir / f\"benchmark_celltype_{file_suffix}.tsv\", sep=\"\\t\", index=True)\n",
    "    print(f\"‚úÖ Benchmark results saved to: {save_dir / f'benchmark_celltype_{file_suffix}.tsv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_celltype.to_csv(save_dir / f\"combined_celltype_{file_suffix}.tsv\", sep=\"\\t\", index=True)\n",
    "print(f\"‚úÖ Combined cell type results saved to: {save_dir / f'combined_celltype_{file_suffix}.tsv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concord",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
