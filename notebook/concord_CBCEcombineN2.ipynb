{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concord as ccd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_dir = Path('../data/CBCEcombineN2')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "import time\n",
    "from pathlib import Path\n",
    "proj_name = \"CBCEcombineN2\"\n",
    "save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\n",
    "save_dir = Path(save_dir)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "file_suffix = f\"{time.strftime('%b%d-%H%M')}\"\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2_adata = sc.read_h5ad('../data/celegans_binyamin/N2_outs/concord_celN2_Jun12-1457.h5ad')\n",
    "cbce_adata = sc.read_h5ad('../data/CE_CB/adata_cbce_Jan30-1028.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved adata to ../data/CBCEcombineN2/CBCEcombineN2_Jun28-1823.h5ad\n"
     ]
    }
   ],
   "source": [
    "n2_adata.obs['embryo.time'] = n2_adata.obs['raw.embryo.time']\n",
    "n2_adata.obs['batch'] = 'BZ_N2'\n",
    "n2_adata.obs['batch_fine'] = 'BZ_N2'\n",
    "n2_adata.obs['batch_broad'] = 'BZ_N2'\n",
    "n2_adata.obs['species'] = 'C.elegans'\n",
    "n2_adata.obs_names = [f\"{name}-BZ_N2\" for name in n2_adata.obs_names]\n",
    "\n",
    "cbce_adata.obs['batch_fine'] = cbce_adata.obs['batch'].copy()\n",
    "cbce_adata.obs['batch_broad'] = cbce_adata.obs['dataset3'].astype(str).copy()\n",
    "adata = cbce_adata.concatenate(n2_adata, batch_key='lab', batch_categories=['Murray_CBCE','Gartner_BZ'])\n",
    "adata.X = adata.layers[\"counts\"].copy()\n",
    "# Compute basic statistics\n",
    "sc.pp.calculate_qc_metrics(adata, inplace=True)\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "adata.obs['batch'] = adata.obs['batch_broad'].copy()\n",
    "sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=10000, subset=False)\n",
    "sc.tl.pca(adata, n_comps=300, svd_solver='arpack', use_highly_variable=True)\n",
    "\n",
    "adata.write_h5ad(data_dir / f\"{proj_name}_{file_suffix}.h5ad\") # Save the adata object with the encoded embeddings\n",
    "print(f\"Saved adata to {data_dir / f'{proj_name}_{file_suffix}.h5ad'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique batches: ['Waterston_300_minutes', 'Waterston_400_minutes', 'Waterston_500_1_minutes', 'Waterston_500_2_minutes', 'Ce_M03D44_300_minutes', ..., 'batch_300', 'batch_360', 'batch_400', 'batch_500', 'BZ_N2']\n",
      "Length: 22\n",
      "Categories (22, object): ['BZ_N2', 'Ce_M03D44_300_minutes', 'Ce_M03D44_500_minutes', 'Ce_ceh9_300_minutes', ..., 'batch_300', 'batch_360', 'batch_400', 'batch_500']\n",
      "Filtered batches: ['Waterston_300_minutes', 'Waterston_400_minutes', 'Waterston_500_1_minutes', 'Waterston_500_2_minutes', 'Murray_b01', 'Murray_b02', 'Murray_r17', 'BZ_N2']\n",
      "adata_celsub shape: (94276, 13405)\n"
     ]
    }
   ],
   "source": [
    "# Save Packer dataset + N2 dataset separately\n",
    "unique_batches = adata.obs['batch_broad'].unique()\n",
    "print(f\"Unique batches: {unique_batches}\")\n",
    "# If the batch name contains Waterston, Murray or BZ_N2, get it\n",
    "filtered_batches = [batch for batch in unique_batches if 'Waterston' in batch or 'Murray' in batch or 'BZ_N2' in batch]\n",
    "print(f\"Filtered batches: {filtered_batches}\")\n",
    "adata_celsub = adata[adata.obs['batch_broad'].isin(filtered_batches)].copy()\n",
    "print(f\"adata_celsub shape: {adata_celsub.shape}\")\n",
    "adata_celsub.write_h5ad(data_dir / f\"adata_celsub_{file_suffix}.h5ad\")\n",
    "print(f\"Saved adata_celsub to {data_dir / f'adata_celsub_{file_suffix}.h5ad'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../data/CBCEcombineN2/CBCEcombineN2_Jun28-1823.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = \"CBCEcombineN2\"\n",
    "file_name = \"CBCEcombineN2\"\n",
    "file_suffix = time.strftime('%b%d-%H%M')\n",
    "seed = 0\n",
    "\n",
    "save_dir = Path(f\"../save/{proj_name}\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = Path(f\"../data/{proj_name}\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessed data saved to ../data/CBCEcombineN2/CBCEcombineN2_preprocessed.h5ad\n"
     ]
    }
   ],
   "source": [
    "adata = adata[:, adata.var.highly_variable].copy()\n",
    "adata.write_h5ad(data_dir / f\"{file_name}_preprocessed.h5ad\")\n",
    "print(f\"✅ Preprocessed data saved to {data_dir / f'{file_name}_preprocessed.h5ad'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisCello project created at ../data/CBCEcombineN2/viscello_CBCEcombineN2\n"
     ]
    }
   ],
   "source": [
    "ccd.ul.anndata_to_viscello(adata,\n",
    "                        output_dir=data_dir / f\"viscello_{proj_name}\",\n",
    "                        project_name=proj_name,\n",
    "                        organism='cel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(data_dir / f\"{proj_name}_preprocessed.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if nan in adata.obs['batch'], if so show the rows with nan\n",
    "if adata.obs['batch'].isna().any():\n",
    "    print(\"Rows with NaN in 'batch':\")\n",
    "    print(adata.obs[adata.obs['batch'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concord_args = {\n",
    "        'batch_size':256, # Batch size for training, adjust as needed\n",
    "        'encoder_dims':[1000], # Encoder dimensions, recommended to be larger than latent_dim\n",
    "        'element_mask_prob': 0.4, # Probability of masking features, recommended to be between 0.2 and 0.5\n",
    "        'feature_mask_prob': 0.2, # Probability of masking features, recommended to be between 0.2 and 0.5\n",
    "        'clr_temperature': 0.4, # Temperature for contrastive loss, recommended to be between 0.1 and 0.5\n",
    "        'sampler_knn': 1000, # Size of neighbohood for intra-neighborhood sampling\n",
    "        'n_epochs': 15, # Number of epochs for training, adjust as needed\n",
    "        'save_dir': '../'+str(save_dir) # Directory to save the model and results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_scvi.py\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_scvi.sh\n",
      "\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_harmony.py\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_harmony.sh\n",
      "\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_scanorama.py\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_scanorama.sh\n",
      "\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_liger.py\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_liger.sh\n",
      "\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_unintegrated.py\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_unintegrated.sh\n",
      "\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_concord_hcl.py\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_concord_hcl.sh\n",
      "\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_concord_knn.py\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_concord_knn.sh\n",
      "\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_contrastive.py\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_contrastive.sh\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './generate_py_jobs.py', '--proj_name', 'CBCEcombineN2', '--adata_filename', 'CBCEcombineN2_preprocessed.h5ad', '--methods', 'scvi', 'harmony', 'scanorama', 'liger', 'unintegrated', 'concord_hcl', 'concord_knn', 'contrastive', '--batch_key', 'batch', '--state_key', 'None', '--latent_dim', '300', '--output_dir', '../jobs', '--device', 'auto', '--conda_env', 'cellpath', '--mem', '32G', '--runtime', '1:00:00', '--concord_kwargs', '{\"batch_size\": 256, \"encoder_dims\": [1000], \"element_mask_prob\": 0.4, \"feature_mask_prob\": 0.2, \"clr_temperature\": 0.4, \"sampler_knn\": 1000, \"n_epochs\": 15, \"save_dir\": \"../../save/CBCEcombineN2\"}', '--mode', 'wynton'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess, json\n",
    "py_methods = [\"scvi\", \"harmony\", \"scanorama\", \"liger\", \"unintegrated\", \"concord_hcl\", \"concord_knn\", \"contrastive\"]\n",
    "output_dir = '../jobs'\n",
    "device = 'auto'\n",
    "conda_env = 'cellpath'\n",
    "batch_key = 'batch'\n",
    "state_key = 'None'\n",
    "latent_dim = '300'  # Adjust as needed, but should match the encoder_dims in concord_args\n",
    "subprocess.run([\n",
    "    \"python\", \"./generate_py_jobs.py\",\n",
    "    \"--proj_name\", proj_name,\n",
    "    \"--adata_filename\", f\"{file_name}_preprocessed.h5ad\",\n",
    "    \"--methods\", *py_methods,\n",
    "    \"--batch_key\", batch_key,\n",
    "    \"--state_key\", state_key,\n",
    "    \"--latent_dim\", latent_dim,\n",
    "    \"--output_dir\", output_dir,\n",
    "    \"--device\", device,\n",
    "    \"--conda_env\", conda_env,\n",
    "    \"--mem\", \"32G\",  # Adjust memory as needed\n",
    "    \"--runtime\", \"1:00:00\",\n",
    "    \"--concord_kwargs\", json.dumps(concord_args),\n",
    "    \"--mode\", \"wynton\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌  Run “../jobs/benchmark_CBCEcombineN2/submit_all_CBCEcombineN2.sh” to queue every job.\n"
     ]
    }
   ],
   "source": [
    "proj_folder = Path(output_dir) / f\"benchmark_{proj_name}\"   # ../jobs/benchmark_<proj>\n",
    "proj_folder.mkdir(exist_ok=True)                      # defensive\n",
    "\n",
    "submit_all = proj_folder / f\"submit_all_{proj_name}.sh\"\n",
    "with submit_all.open(\"w\") as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    f.write(\"# Auto-generated — submits every job for this project\\n\")\n",
    "    f.write(\"# Run from this folder, or let the script cd into it.\\n\\n\")\n",
    "    f.write('cd \"$(dirname \"$0\")\"\\n\\n')          # ensures we’re in the right dir\n",
    "    for sh_file in sorted(proj_folder.glob(f\"benchmark_{proj_name}_*.sh\")):\n",
    "        f.write(f'qsub \"{sh_file.name}\"\\n')\n",
    "\n",
    "submit_all.chmod(0o755)\n",
    "print(f\"📌  Run “{submit_all}” to queue every job.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_seurat_cca.R\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_seurat_cca.sh\n",
      "\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_seurat_rpca.R\n",
      "✅ Generated: benchmark_CBCEcombineN2/benchmark_CBCEcombineN2_seurat_rpca.sh\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './generate_seurat_script.py', '--proj_name', 'CBCEcombineN2', '--eset_dir', '../../data/CBCEcombineN2/viscello_CBCEcombineN2', '--methods', 'seurat_cca', 'seurat_rpca', '--batch_key', 'batch', '--state_key', 'None', '--latent_dim', '300', '--mem', '250G', '--runtime', '72:00:00', '--output_dir', '../jobs', '--device', 'auto', '--conda_env', 'cellpath'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate script for Seurat\n",
    "import subprocess\n",
    "r_methods = [\"seurat_cca\", \"seurat_rpca\"]\n",
    "output_dir = '../jobs'\n",
    "device = 'auto'\n",
    "conda_env = 'cellpath'\n",
    "batch_key = 'batch'\n",
    "state_key = 'None'\n",
    "latent_dim = '300' \n",
    "subprocess.run([\n",
    "    \"python\", \"./generate_seurat_script.py\",\n",
    "    \"--proj_name\", proj_name,\n",
    "    \"--eset_dir\", '../'+ str(data_dir / f\"viscello_{proj_name}\"),   # <- folder w/ eset.rds\n",
    "    \"--methods\", *r_methods,\n",
    "    \"--batch_key\", batch_key,\n",
    "    \"--state_key\", state_key,\n",
    "    \"--latent_dim\", latent_dim,\n",
    "    \"--mem\", \"250G\",  # Adjust memory as needed\n",
    "    \"--runtime\", \"72:00:00\",\n",
    "    \"--output_dir\", output_dir,\n",
    "    \"--device\", device,\n",
    "    \"--conda_env\", conda_env\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
