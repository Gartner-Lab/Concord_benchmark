{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concord as ccd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_dir = Path('../data/CBCEcombineN2/')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "import time\n",
    "from pathlib import Path\n",
    "proj_name = \"concord_combine_packerN2\"\n",
    "save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\n",
    "save_dir = Path(save_dir)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(data_dir / 'adata_celsub_Jun26-1610.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=10000, subset=False)\n",
    "sc.tl.pca(adata, n_comps=50, svd_solver='arpack', use_highly_variable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ccd.ul.select_features(adata, n_top_features=10000, flavor='seurat_v3') # Loosely select features based on Seurat v3 method (so that enough information is preserved)\n",
    "\n",
    "concord_args = {\n",
    "        'adata': adata,\n",
    "        'input_feature': feature_list,\n",
    "        'domain_key': 'batch', # Key in adata.obs that contains the domain labels\n",
    "        'batch_size':64, # Batch size for training, adjust as needed\n",
    "        'latent_dim': 300, # Latent dimension size, adjust as needed\n",
    "        'encoder_dims':[1000], # Encoder dimensions, recommended to be larger than latent_dim\n",
    "        'use_decoder': False, # Whether to use a decoder, set to True if you want to use the decoder\n",
    "        'decoder_dims':[1000], # Decoder dimensions, ignored if use_decoder is False\n",
    "        'augmentation_mask_prob': 0.3, # Probability of masking features, recommended to be between 0.2 and 0.5\n",
    "        'dropout_prob': 0, # Dropout rate for the model, recommended to be between 0.1 and 0.3\n",
    "        'clr_temperature': 0.3, # Temperature for contrastive loss, recommended to be between 0.1 and 0.5\n",
    "        'clr_beta':0.0,\n",
    "        'p_intra_knn': 0.3, # Probability of intra-neighborhood sampling, must be less than 0.5\n",
    "        'sampler_emb': None,\n",
    "        'sampler_knn': 1000, # Size of neighbohood for intra-neighborhood sampling\n",
    "        'n_epochs': 15, # Number of epochs for training, adjust as needed\n",
    "        'verbose': True, # Verbosity level, set to True for more detailed output\n",
    "        'seed': seed, # random seed for reproducibility\n",
    "        'device': device, # Device for training, can be 'cpu', 'cuda', or 'mps'\n",
    "        'save_dir': save_dir # Directory to save the model and results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_suffix = f\"{time.strftime('%b%d-%H%M')}\"\n",
    "output_key = f'Concord_{file_suffix}'\n",
    "print(f\"Output key: {output_key}\")\n",
    "cur_ccd = ccd.Concord(**concord_args)\n",
    "cur_ccd.fit_transform(output_key=output_key) # Result saved to ccd.adata.obsm[output_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill na with unannotated\n",
    "adata.obs['lineage'].fillna('unannotated', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = output_key\n",
    "file_suffix = f\"{time.strftime('%b%d-%H%M')}\"\n",
    "ccd.ul.run_umap(adata, source_key=basis, result_key=f'{basis}_UMAP', n_components=2, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\n",
    "show_basis = basis + '_UMAP'\n",
    "show_cols = ['plot.cell.type', 'raw.embryo.time', \"batch\", 'dataset', 'lineage']\n",
    "pal = {'plot.cell.type': 'tab20', 'raw.embryo.time': 'BlueGreenRed', \"batch\": 'tab20', 'dataset': 'Set1', 'lineage': 'tab20'}\n",
    "ccd.pl.plot_embedding(\n",
    "    adata, show_basis, show_cols, figsize=(13,8), dpi=600, ncols=3, font_size=5, point_size=2, legend_loc=None, \n",
    "    pal = pal,\n",
    "    save_path=save_dir / f\"{show_basis}_{file_suffix}.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd.ul.run_umap(adata, source_key=basis, result_key=f'{basis}_UMAP_3D', n_components=3, n_neighbors=30, min_dist=0.1, metric='euclidean', random_state=seed)\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "for col in show_cols:\n",
    "    show_basis = f'{basis}_UMAP_3D'\n",
    "    ccd.pl.plot_embedding_3d(\n",
    "            adata, basis=show_basis, color_by=col,\n",
    "            pal = pal[col],\n",
    "            save_path=save_dir / f'{show_basis}_{col}_{file_suffix}.html',\n",
    "            point_size=1, opacity=0.8, width=1500, height=1000\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(data_dir / f\"{proj_name}_{file_suffix}.h5ad\") # Save the adata object with the encoded embeddings\n",
    "print(f\"Saved adata to {data_dir / f'{proj_name}_{file_suffix}.h5ad'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd.ul.anndata_to_viscello(adata, data_dir / f\"cello_{proj_name}_{file_suffix}\", project_name = proj_name, organism='hsa')\n",
    "print(f\"Saved viscello to {data_dir / f'cello_{proj_name}_{file_suffix}'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Probe evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_keys = adata.obsm.keys()\n",
    "# Exclude UMAP keys\n",
    "eval_keys = [key for key in eval_keys if 'UMAP' not in key]\n",
    "eval_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any of raw.embryo.time is na\n",
    "if adata.obs['raw.embryo.time'].isna().any():\n",
    "    print(\"Warning: raw.embryo.time contains NA values. Please check your data.\")\n",
    "\n",
    "if adata.obs['plot.cell.type'].isna().any():\n",
    "    sum_na = adata.obs['plot.cell.type'].isna().sum()\n",
    "    print(f\"Warning: plot.cell.type contains {sum_na} NA values. \")\n",
    "\n",
    "# Set na values to \"unannotated\"\n",
    "adata.obs['plot.cell.type'].fillna('unannotated', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concord.benchmarking import LinearProbeEvaluator\n",
    "target_keys = ['raw.embryo.time', 'plot.cell.type', 'lineage', 'batch']  \n",
    "ignore_values=['unannotated'],  # ignore unannotated cells\n",
    "linear_results = {}\n",
    "for target_key in target_keys:\n",
    "    print(f\"Evaluating {target_key}...\")\n",
    "    evaluator = LinearProbeEvaluator(\n",
    "        adata=adata,\n",
    "        emb_keys=eval_keys,\n",
    "        target_key=target_key,          # or \"pseudotime\"\n",
    "        task=\"auto\",                     # \"auto\" | \"classification\" | \"regression\"\n",
    "        batch_size=128,\n",
    "        lr=1e-2,\n",
    "        weight_decay=1e-3,\n",
    "        epochs=20,                        # default replicates HCL\n",
    "        print_every=1,\n",
    "        ignore_values=ignore_values,  # ignore unannotated cells\n",
    "        return_preds=True,          # whether to return predictions\n",
    "        device=\"cpu\"                    # or \"cpu\"\n",
    "    )\n",
    "    results_df, pred_bank = evaluator.run()\n",
    "    linear_results[target_key] = results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concord.benchmarking import KNNProbeEvaluator\n",
    "knneval_results = {}\n",
    "for target_key in target_keys:\n",
    "    print(f\"Evaluating {target_key} with KNN...\")\n",
    "    knn_eval = KNNProbeEvaluator(\n",
    "        adata         = adata,\n",
    "        emb_keys      = eval_keys,\n",
    "        target_key    = target_key,  \n",
    "        ignore_values = ignore_values,  # ignore unannotated cells\n",
    "        k             = 15,\n",
    "        metric        = \"euclidean\",   # or \"cosine\"\n",
    "        return_preds  = True,\n",
    "        seed          = 0,\n",
    "    )\n",
    "    metrics_df, preds_bank = knn_eval.run()\n",
    "    knneval_results[target_key] = metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineage graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import lineage_helpers          # already imported earlier\n",
    "import pandas as pd\n",
    "\n",
    "importlib.reload(lineage_helpers)   # reloads the .py file from disk\n",
    "\n",
    "from lineage_helpers import build_lineage_graph  # re-import the updated function\n",
    "\n",
    "\n",
    "tbl = pd.read_csv(\"../data/CE_CB/cel_lineage_tree_tbl.csv\", index_col=0)\n",
    "\n",
    "G_tree, tbl_aug = build_lineage_graph(\n",
    "        adata, tbl,\n",
    "        broad_lineage_groups=None,\n",
    "        add_broad_group=True,\n",
    "        plot=True,\n",
    "        plot_path=save_dir / \"lineage_tree.pdf\",\n",
    ")\n",
    "print(tbl_aug[\"mapped\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lineage_helpers import assign_cells_to_tree, compute_node_medoids\n",
    "_ = assign_cells_to_tree(G_tree, adata,\n",
    "                         lineage_key=\"lineage\",\n",
    "                         celltype_key=\"plot.cell.type\",\n",
    "                         prefer=\"lineage\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) compute medoids on your 2-D Concord embedding\n",
    "_ = compute_node_medoids(G_tree, adata,\n",
    "                         emb_key=\"Concord_Jun21-1419\",\n",
    "                         method=\"medoid\",\n",
    "                         jitter=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, lineage_helpers as lh\n",
    "importlib.reload(lh)                       # grab the new code\n",
    "\n",
    "D_euc, nodes = lh.pairwise_embedding_distances(\n",
    "    G_tree, adata,\n",
    "    emb_key=\"Concord_Jun21-1419\",\n",
    "    metric=\"euclidean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geodesic distances (hop-weighted) on a 30-NN graph\n",
    "import importlib, lineage_helpers as lh\n",
    "D_geo, _ = lh.pairwise_geodesic_distances(\n",
    "    G_tree, adata,\n",
    "    rep_key=\"Concord_Jun21-1419\",\n",
    "    n_neighbors=30,\n",
    "    directed=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_lin, _ = lh.pairwise_lineage_distances(\n",
    "    G_tree.to_undirected()      # make sure it's undirected for path length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p, z = lh.mantel_correlation(D_lin, D_geo, method=\"spearman\", permutations=999)\n",
    "print(f\"Mantel r = {r:.3f}, p = {p:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of geo distances \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(D_lin, annot=False,cmap='viridis')\n",
    "plt.title(\"Geodesic Distances on Lineage Tree\")\n",
    "plt.savefig(save_dir / \"geodesic_distances_heatmap.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lineage \n",
    "output_key = 'Concord_Jun21-1419'\n",
    "sc.pp.neighbors(adata, use_rep=output_key, n_neighbors=30)  # or faiss     # sparse scipy CSR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_key = adata.uns[\"neighbors\"][\"connectivities_key\"]   # usually just 'connectivities'\n",
    "dist_key = adata.uns[\"neighbors\"][\"distances_key\"]        # usually 'distances'\n",
    "\n",
    "G = adata.obsp[conn_key]      # sparse CSR matrix (cells × cells)\n",
    "D = adata.obsp[dist_key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "medoid_idx = {}\n",
    "medoid_coord = {}\n",
    "for lin in adata.obs[\"lineage\"].cat.categories:\n",
    "    idx = np.where(adata.obs[\"lineage\"] == lin)[0]\n",
    "    coords = adata.obsm[output_key][idx, :]\n",
    "    medoid_coord[lin], medoid_idx[lin] = get_representative_point(coords, method=\"medoid\", return_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick helper\n",
    "\n",
    "output_key = 'Concord_Jun21-1419'\n",
    "lineage_to_cells = (\n",
    "    adata.obs.groupby('lineage')\n",
    "         .indices              # dict {lineage_name: ndarray of cell indices}\n",
    ")\n",
    "celltype_to_cells = (\n",
    "    adata.obs.groupby('plot.cell.type')\n",
    "            .indices              # dict {celltype_name: ndarray of cell indices}\n",
    ")\n",
    "\n",
    "# attach the medoid (or full index list) as a node attribute\n",
    "for n,data in G_tree.nodes(data=True):\n",
    "    lineage_mapped = data.get('lineage_annot', None)\n",
    "    # If lineage_mapped is None, or if is na, then skip\n",
    "    if lineage_mapped is None or (isinstance(lineage_mapped, float) and pd.isna(lineage_mapped)):\n",
    "        continue\n",
    "\n",
    "    cells = []\n",
    "    print(f\"Processing node {n} with lineage {lineage_mapped}\")\n",
    "    for lin in lineage_mapped:\n",
    "        if lin in lineage_to_cells:\n",
    "            cells.extend(lineage_to_cells[lin])\n",
    "            break\n",
    "    if len(cells) == 0:\n",
    "        continue          # node not present in adata – skip later\n",
    "    # medoid = cell that minimises sum of squared Euclidean distances\n",
    "    Z   = adata.obsm[output_key][cells]\n",
    "    d2  = ((Z[:,None,:] - Z[None,:,:])**2).sum(-1)\n",
    "    medoid = cells[np.argmin(d2.sum(0))]\n",
    "    data[\"medoid\"] = medoid\n",
    "    data[\"cells\"]  = cells               # keep full set in case you want avg/min\n",
    "    print(f\"Node {n} has {len(cells)} cells, medoid index: {medoid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep=output_key, n_neighbors=30, key_added=\"concord_nn\")\n",
    "conn_key = adata.uns[\"concord_nn\"][\"connectivities_key\"]\n",
    "G_knn = adata.obsp[conn_key].tocsr()         # SciPy CSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_nodes, medoid_idx = [], []\n",
    "\n",
    "for n, data in G_tree.nodes(data=True):\n",
    "    medoid = data.get(\"medoid\", None)      # returns None if key missing\n",
    "    if medoid is None or np.isnan(medoid):\n",
    "        # ‒ lineage not present in the AnnData, or medoid not yet computed\n",
    "        #   you can log / warn here if you want to know which ones were skipped\n",
    "        continue\n",
    "    lin_nodes.append(n)\n",
    "    medoid_idx.append(int(medoid))\n",
    "\n",
    "medoid_idx = np.asarray(medoid_idx, dtype=int)\n",
    "L = len(lin_nodes)\n",
    "print(f\"Using {L} lineage nodes that have valid medoids.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse.csgraph as cg\n",
    "import numpy as np\n",
    "\n",
    "# medoid_idx and lin_nodes already prepared in your previous step\n",
    "dist_src_all = cg.dijkstra(G_knn,\n",
    "                           directed=False,\n",
    "                           indices=medoid_idx)   # shape (L × V)\n",
    "\n",
    "# keep only the L target columns you care about\n",
    "dist_lin_all = dist_src_all[:, medoid_idx]       # shape (L × L)\n",
    "\n",
    "# For clarity, build a lookup table node → row/col\n",
    "lin2row = {n: i for i, n in enumerate(lin_nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of distances\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(dist_lin_all, cmap='viridis', cbar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lin_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import scipy.sparse.csgraph as cg\n",
    "import networkx as nx\n",
    "from ete3 import Tree\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Build MST on latent distance matrix\n",
    "# ------------------------------------------------------------------\n",
    "mst_sparse = cg.minimum_spanning_tree(sp.csr_matrix(dist_lin_all))\n",
    "mst_graph  = nx.Graph(mst_sparse)           # undirected, L nodes, L-1 edges\n",
    "\n",
    "mapping    = {i: lin_nodes[i] for i in range(len(lin_nodes))}\n",
    "mst_graph  = nx.relabel_nodes(mst_graph, mapping, copy=False)\n",
    "\n",
    "# optional: root at the zygote (‘P0’) so you can compare branch lengths\n",
    "root_node  = \"P0\" if \"P0\" in lin_nodes else lin_nodes[0]\n",
    "mst_rooted = nx.bfs_tree(mst_graph, source=root_node).to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute UMAP based on the distances\n",
    "import umap\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=15,  # or adjust based on your data\n",
    "    min_dist=0.1,\n",
    "    metric='precomputed',\n",
    "    random_state=42\n",
    ")\n",
    "umap_embedding = umap_model.fit_transform(dist_lin_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MST\n",
    "plt.figure(figsize=(30, 20))\n",
    "pos = nx.spring_layout(mst_rooted, seed=42)  # positions for all nodes\n",
    "nx.draw(mst_rooted, pos, with_labels=True, node_size=300, node_color='lightblue', font_size=7, font_color='black', edge_color='gray')\n",
    "plt.savefig(save_dir/\"mst_tree.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import numpy as np\n",
    "\n",
    "# -- Map lineage node → point in the UMAP embedding --------------------------\n",
    "pos = {node: umap_embedding[i]                # dict  {node: (x, y)}\n",
    "       for i, node in enumerate(lin_nodes)}\n",
    "\n",
    "# -- Build a list of edge segments -------------------------------------------\n",
    "segments = []\n",
    "for parent, child in G_tree.edges():\n",
    "    if parent in pos and child in pos:        # skip missing medoids\n",
    "        segments.append([pos[parent], pos[child]])\n",
    "\n",
    "# Optionally colour-code by lineage depth or anything in node attributes\n",
    "edge_colors = \"grey\"          # or a list the same length as segments\n",
    "edge_lw     = 0.6             # thin lines keep the plot readable\n",
    "\n",
    "# -- Plot --------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 7), dpi=150)\n",
    "\n",
    "# scatter (medoids)\n",
    "ax.scatter(umap_embedding[:, 0],\n",
    "           umap_embedding[:, 1],\n",
    "           s       = 12,\n",
    "           alpha   = 0.9,\n",
    "           zorder  = 3,\n",
    "           edgecolors=\"none\")\n",
    "\n",
    "# edges\n",
    "lc = LineCollection(segments,\n",
    "                    colors=edge_colors,\n",
    "                    linewidths=edge_lw,\n",
    "                    alpha=0.7,\n",
    "                    zorder=2)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# (optional) annotate lineage labels\n",
    "for node, (x, y) in pos.items():\n",
    "    ax.annotate(node,\n",
    "                xy=(x, y),\n",
    "                xytext=(2, 2),\n",
    "                textcoords=\"offset points\",\n",
    "                fontsize=3,\n",
    "                alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"UMAP 1\")\n",
    "ax.set_ylabel(\"UMAP 2\")\n",
    "ax.set_title(\"UMAP of lineage medoids with true tree overlay\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir / \"umap_lineage_tree_overlay.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_points = [\n",
    "    n for n in G_tree.nodes()\n",
    "    if G_tree.out_degree(n) >= 2\n",
    "       and all(\"medoid\" in G_tree.nodes[c] for c in G_tree.successors(n))\n",
    "]\n",
    "\n",
    "print(f\"{len(branch_points)} branch points with ≥2 mapped daughters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# helpers ---------------------------------------------------------------\n",
    "def _as_iter(x):\n",
    "    \"\"\"None → []; str → [str]; list/tuple → list\"\"\"\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return list(x)\n",
    "    return [x]          # single string\n",
    "\n",
    "def _indices_from_names(names, mapping_dict):\n",
    "    \"\"\"Concatenate index lists for all present names\"\"\"\n",
    "    out = []\n",
    "    for n in names:\n",
    "        out.extend(mapping_dict.get(n, []))\n",
    "    return out\n",
    "\n",
    "# main ------------------------------------------------------------------\n",
    "def cells_of_lineage(node):\n",
    "    \"\"\"\n",
    "    Return np.ndarray of cell indices that belong to the lineage node.\n",
    "    Sources checked, in order:\n",
    "      1. node.linannot   (list or string) in lineage_to_cells\n",
    "      2. node.celltype   (list or string) in celltype_to_cells\n",
    "      3. node.linorct    (mixed list)     in either dict\n",
    "      4. the node *name* itself in lineage_to_cells\n",
    "    \"\"\"\n",
    "    data = G_tree.nodes[node]          # attribute dict\n",
    "\n",
    "    idx = []\n",
    "    # 1 & 2. explicit mappings\n",
    "    idx += _indices_from_names(_as_iter(data.get(\"linannot\")),\n",
    "                               lineage_to_cells)\n",
    "    idx += _indices_from_names(_as_iter(data.get(\"celltype\")),\n",
    "                               celltype_to_cells)\n",
    "    # 3. combined mapping field linorct\n",
    "    for name in _as_iter(data.get(\"linorct\")):\n",
    "        if name in lineage_to_cells:\n",
    "            idx.extend(lineage_to_cells[name])\n",
    "        elif name in celltype_to_cells:\n",
    "            idx.extend(celltype_to_cells[name])\n",
    "\n",
    "    # 4. fallback: node label may match lineage_to_cells directly\n",
    "    if not idx and node in lineage_to_cells:\n",
    "        idx.extend(lineage_to_cells[node])\n",
    "\n",
    "    return np.unique(idx)              # deduplicate & sort\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_to_cells = (\n",
    "    adata.obs.groupby('lineage')\n",
    "         .indices              # dict {lineage_name: ndarray of cell indices}\n",
    ")\n",
    "celltype_to_cells = (\n",
    "    adata.obs.groupby('plot.cell.type')\n",
    "            .indices              # dict {celltype_name: ndarray of cell indices}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_key = 'Concord_Jun21-1419'  # or whatever your embedding key is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,data in G_tree.nodes(data=True):\n",
    "    cells = cells_of_lineage(n)\n",
    "    print(f\"Node {n} has {len(cells)} cells in lineage\")\n",
    "    if cells.size == 0:\n",
    "        continue\n",
    "    Z = adata.obsm[latent_key][cells]\n",
    "    d2 = ((Z[:,None,:] - Z[None,:,:])**2).sum(-1).sum(0)\n",
    "    data[\"medoid\"] = int(cells[np.argmin(d2)])\n",
    "    data[\"cells\"]  = cells               # keep full set if needed l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2.  IDENTIFY BRANCH POINTS AND COLLECT CELLS\n",
    "# ------------------------------------------------------------------------------\n",
    "branch_points = [\n",
    "    n for n in G_tree.nodes()\n",
    "    if G_tree.out_degree(n) >= 2\n",
    "       and sum(cells_of_lineage(ch).size > 0 for ch in G_tree.successors(n)) >= 2\n",
    "]\n",
    "\n",
    "triplet_data = {}\n",
    "for p in branch_points:\n",
    "    daughters  = [ch for ch in G_tree.successors(p) if cells_of_lineage(ch).size]\n",
    "    if len(daughters) < 2:\n",
    "        continue\n",
    "    cells = np.concatenate([\n",
    "        cells_of_lineage(p),\n",
    "        *[cells_of_lineage(d) for d in daughters]\n",
    "    ])\n",
    "    if cells.size == 0:\n",
    "        continue\n",
    "    triplet_data[p] = dict(daughters=daughters[:2],  # keep first 2 for Y-split\n",
    "                           cells=cells)\n",
    "\n",
    "print(f\"Found {len(triplet_data)} branch points with ≥2 mapped daughters.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 3.  CORE ROUTINES\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.csgraph as cg\n",
    "import umap, numpy as np, matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import pandas as pd\n",
    "\n",
    "n_neighbors=10\n",
    "def build_subgraph(cells):\n",
    "    Z = adata.obsm[latent_key][cells]\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(Z)\n",
    "    knn_idx, knn_dist = nbrs.kneighbors(Z, return_distance=True)\n",
    "    rows = np.repeat(np.arange(len(cells)), n_neighbors)\n",
    "    G = sp.csr_matrix((knn_dist.flatten(),\n",
    "                       (rows, knn_idx.flatten())),\n",
    "                      shape=(len(cells), len(cells)))\n",
    "    return Z, G\n",
    "\n",
    "def embed_subgraph(dists):\n",
    "    um = umap.UMAP(n_neighbors=n_neighbors,\n",
    "                   min_dist=0.1,\n",
    "                   metric=\"precomputed\",\n",
    "                   random_state=42)\n",
    "    return um.fit_transform(dists)\n",
    "\n",
    "def branch_metrics(parent_mask, d1_mask, d2_mask, Z):\n",
    "    z_p  = Z[parent_mask].mean(0)\n",
    "    z_d1 = Z[d1_mask   ].mean(0)\n",
    "    z_d2 = Z[d2_mask   ].mean(0)\n",
    "    d_pd = (np.linalg.norm(z_p-z_d1) + np.linalg.norm(z_p-z_d2)) / 2\n",
    "    d_dd =  np.linalg.norm(z_d1-z_d2)\n",
    "    return d_pd, d_dd\n",
    "\n",
    "def plot_triplet(p, daughters, cells, Z, X, out_png):\n",
    "    # colour by label\n",
    "    labels = np.full(len(cells), p, dtype=object)\n",
    "    labels[np.isin(cells, cells_of_lineage(daughters[0]))] = daughters[0]\n",
    "    labels[np.isin(cells, cells_of_lineage(daughters[1]))] = daughters[1]\n",
    "    lut = {p:\"#636363\",\n",
    "           daughters[0]:\"#4575b4\",\n",
    "           daughters[1]:\"#d73027\"}\n",
    "    colors = [lut[l] for l in labels]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4,4), dpi=200)\n",
    "    ax.scatter(X[:,0], X[:,1], s=6, c=colors, alpha=.9, rasterized=True)\n",
    "    # MST skeleton for clarity\n",
    "    mst = cg.minimum_spanning_tree(squareform(pdist(Z)))\n",
    "    segs = [[X[i], X[j]] for i,j in zip(*mst.nonzero())]\n",
    "    ax.add_collection(LineCollection(segs, colors=\"#00000055\", lw=.6))\n",
    "    ax.set_title(f\"{p} → {daughters[0]}, {daughters[1]}\")\n",
    "    ax.axis(\"off\")\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_data['ABalaaa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = triplet_data['ABalaaa']\n",
    "daughters = info[\"daughters\"]        # two daughters\n",
    "cells     = info[\"cells\"]\n",
    "Z, G_sub  = build_subgraph(cells)\n",
    "dists_sub = cg.dijkstra(G_sub, directed=False, indices=None)  # full matrix\n",
    "X_2d      = embed_subgraph(dists_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 4.  RUN LOOP: make plots and metrics  (UMAP-from-latent version)\n",
    "# ------------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "for p, info in triplet_data.items():\n",
    "    daughters = info[\"daughters\"]            # two daughters\n",
    "    cells     = np.asarray(info[\"cells\"], int)\n",
    "    print(f\"Processing {p} → {daughters[0]}, {daughters[1]}  (n={len(cells)})\")\n",
    "\n",
    "    # latent vectors of the triplet\n",
    "    Z, _ = build_subgraph(cells)             # Z = latent coords; G_sub unused now\n",
    "\n",
    "    # --- NEW: UMAP directly on Z (Euclidean metric) --------------------------\n",
    "    um = umap.UMAP(n_neighbors=n_neighbors,\n",
    "                   min_dist=0.1,\n",
    "                   metric=\"euclidean\",\n",
    "                   random_state=42)\n",
    "    X_2d = um.fit_transform(Z)               # shape (n_cells, 2)\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    # masks for the metrics\n",
    "    lab_p  = np.isin(cells, cells_of_lineage(p))\n",
    "    lab_d1 = np.isin(cells, cells_of_lineage(daughters[0]))\n",
    "    lab_d2 = np.isin(cells, cells_of_lineage(daughters[1]))\n",
    "    d_pd, d_dd = branch_metrics(lab_p, lab_d1, lab_d2, Z)\n",
    "\n",
    "    results.append(dict(parent=p,\n",
    "                        daughter1=daughters[0],\n",
    "                        daughter2=daughters[1],\n",
    "                        d_parent_daughter=d_pd,\n",
    "                        d_daughter_daughter=d_dd,\n",
    "                        ratio=d_dd/d_pd if d_pd else np.nan))\n",
    "\n",
    "    # plot & save\n",
    "    out_png = save_dir / f\"triplet_{p.replace(' ', '_')}.png\"\n",
    "    plot_triplet(p, daughters, cells, Z, X_2d, out_png)\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "metrics_df.to_csv(save_dir / \"branch_metrics.csv\", index=False)\n",
    "print(\"✓ Finished.   Plots →\", save_dir,\n",
    "      \"\\n              Metrics →\", save_dir / \"branch_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm[latent_key][cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X  = your geodesic distance matrix from the latent\n",
    "#      shape (L × L), order given by `lin_nodes`\n",
    "X = dist_lin_all\n",
    "\n",
    "# Build biological path-length matrix Y using the ground-truth tree\n",
    "import networkx as nx, numpy as np, pandas as pd, scipy.sparse.csgraph as cg\n",
    "\n",
    "lin2row = {n: i for i, n in enumerate(lin_nodes)}     # helper\n",
    "\n",
    "# 0.1  choose edge weight\n",
    "#   a)  plain edge count                (every division = 1)\n",
    "#   b)  embryo time difference          (if you have time per node)\n",
    "edge_weight = \"count\"                  # or \"time\"\n",
    "\n",
    "def true_path_matrix(G_tree, lin_nodes, edge_weight=\"count\"):\n",
    "    L  = len(lin_nodes)\n",
    "    Y  = np.full((L, L), np.inf)\n",
    "    for i,u in enumerate(lin_nodes):\n",
    "        Y[i,i] = 0\n",
    "        for j,v in enumerate(lin_nodes[i+1:], i+1):\n",
    "            try:\n",
    "                if edge_weight == \"count\":\n",
    "                    d = nx.shortest_path_length(G_tree, u, v)\n",
    "                else:\n",
    "                    # sum embryo time differences along path\n",
    "                    path = nx.shortest_path(G_tree, u, v)\n",
    "                    t = nx.get_node_attributes(G_tree, \"embryo_time\")\n",
    "                    d = sum(abs(t[path[k]] - t[path[k+1]]) for k in range(len(path)-1))\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "            Y[i,j] = Y[j,i] = d\n",
    "    return Y\n",
    "\n",
    "Y = true_path_matrix(G_tree, lin_nodes, edge_weight=\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concord",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
