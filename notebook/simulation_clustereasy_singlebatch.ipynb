{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation using Concord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import time\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import concord as ccd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "\n",
    "from matplotlib import font_manager, rcParams\n",
    "custom_rc = {\n",
    "    'font.family': 'Arial',  # Set the desired font for this plot\n",
    "}\n",
    "\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = \"simulation_clustereasy_singlebatch\"\n",
    "save_dir = f\"../save/dev_{proj_name}-{time.strftime('%b%d')}/\"\n",
    "save_dir = Path(save_dir)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = f\"../data/{proj_name}/\"\n",
    "data_dir = Path(data_dir)\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "seed = 0\n",
    "ccd.ul.set_seed(seed)\n",
    "\n",
    "file_suffix = f\"{time.strftime('%b%d-%H%M')}\"\n",
    "file_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_key = 'cluster'\n",
    "batch_key = 'batch'\n",
    "state_type = 'cluster'\n",
    "leiden_key='leiden'\n",
    "batch_type = 'batch_specific_features'\n",
    "distribution = 'normal'\n",
    "n_cells = [100,100,50]\n",
    "n_genes = [100,100,50]\n",
    "state_dispersion = [4.0,2.0,2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Concord.utils.simulation import Simulation\n",
    "\n",
    "sim = Simulation(n_cells=n_cells, n_genes=n_genes,\n",
    "                 n_batches=1, n_states=3, \n",
    "                 state_type=state_type, \n",
    "                 state_distribution = distribution, \n",
    "                 state_level=5, \n",
    "                 state_min_level=0,\n",
    "                 state_dispersion=state_dispersion, \n",
    "                 program_structure=\"uniform\",\n",
    "                 program_on_time_fraction=0.3,\n",
    "                 trajectory_program_num=4,\n",
    "                 trajectory_loop_to=[1],\n",
    "                 batch_feature_frac=0.15,\n",
    "                 batch_distribution = distribution,\n",
    "                 batch_type=batch_type, \n",
    "                 batch_level=[5,5], \n",
    "                 batch_dispersion=[3.0, 3.0], \n",
    "                 global_non_specific_gene_fraction=0.1,\n",
    "                 pairwise_non_specific_gene_fraction=None,\n",
    "                 non_neg=True, to_int=True,\n",
    "                 seed=seed)\n",
    "\n",
    "# Generate the simulated data\n",
    "adata, adata_state = sim.simulate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd.pl.heatmap_with_annotations(adata, val='no_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state', save_path=save_dir/f'true_state_heatmap_{file_suffix}.svg', figsize=(6, 4), dpi=300)\n",
    "ccd.pl.heatmap_with_annotations(adata, val='wt_noise', obs_keys=[state_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='True state with noise', save_path=save_dir/f'true_state_with_noise_heatmap_{file_suffix}.svg', figsize=(6, 4), dpi=300)\n",
    "ccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key], yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Simulated data with batch signal', save_path=save_dir/f'simulated_data_heatmap_{file_suffix}.svg', figsize=(6, 4), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No batch effect, no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 15\n",
    "ccd.ul.run_pca(adata, source_key='no_noise', result_key='PCA_no_noise', n_pc=n_components, random_state=seed)\n",
    "ccd.ul.run_umap(adata, source_key='no_noise', result_key='UMAP_no_noise', random_state=seed)\n",
    "sc.pp.neighbors(adata, use_rep='PCA_no_noise', n_neighbors=30, random_state=seed)\n",
    "sc.tl.leiden(adata, resolution=1.0, key_added=leiden_key, random_state=seed)\n",
    "#adata.obs[leiden_key] = adata_state.obs[leiden_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_basis = 'PCA_no_noise'\n",
    "show_cols = [state_key, batch_key, leiden_key]\n",
    "\n",
    "ccd.pl.plot_embedding(\n",
    "    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n",
    "    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_basis = 'UMAP_no_noise'\n",
    "\n",
    "ccd.pl.plot_embedding(\n",
    "    adata, show_basis, show_cols, figsize=(8,3), dpi=300, ncols=3, font_size=5, point_size=20, legend_loc='on data',\n",
    "    save_path=save_dir / f\"nobatch_{show_basis}_{file_suffix}.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noise added, Run all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_methods = [\"PCA\", \"UMAP\", \"t-SNE\", \"DiffusionMap\", \"NMF\", \n",
    "             \"FactorAnalysis\", \"FastICA\", \"LDA\", \"ZIFA\", \"scVI\", \"PHATE\", \n",
    "             \"Concord\", \"Concord-decoder\", \"Concord-pknn0\"]\n",
    "# exclude [\"UMAP\", \"t-SNE\"] from run_method, and save as combined_keys\n",
    "exclude_keys = [\"PCA\", \"UMAP\", \"t-SNE\"]\n",
    "combined_keys = ['no_noise', 'wt_noise'] + [key for key in run_methods if key not in exclude_keys]\n",
    "combined_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_log = ccd.ul.run_dimensionality_reduction_pipeline(\n",
    "    adata,\n",
    "    source_key=\"X\",\n",
    "    methods=run_methods,\n",
    "    n_components=15,\n",
    "    random_state=seed,\n",
    "    device=device,\n",
    "    save_dir=save_dir,\n",
    "    concord_epochs=15,\n",
    "    concord_min_pid=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run umap and PCA for all latent embeddings\n",
    "adata.obsm['no_noise'] = adata.layers['no_noise']\n",
    "adata.obsm['wt_noise'] = adata.layers['wt_noise']\n",
    "max_pc = 15\n",
    "for basis in combined_keys:\n",
    "    print(\"Running UMAP and PCA for\", basis)\n",
    "    #if 'UMAP' not in basis:\n",
    "    ccd.ul.run_umap(adata, source_key=basis, result_key=f'{basis}_UMAP', n_components=2, n_neighbors=30, min_dist=0.5, metric='euclidean', random_state=seed)\n",
    "    if not any(substring in basis for substring in ['PHATE', 'PCA']):\n",
    "        if basis in adata.layers.keys():\n",
    "            n_pc = min(min(adata.layers[basis].shape[1], adata.shape[0]) - 1, max_pc)\n",
    "        else:\n",
    "            n_pc = min(min(adata.obsm[basis].shape[1], adata.shape[0]) - 1, max_pc)\n",
    "        \n",
    "        print(\"n_pc\", n_pc)\n",
    "        ccd.ul.run_pca(adata, source_key=basis, result_key=f'{basis}_PCA', n_pc=n_pc, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot everything\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import font_manager, rcParams\n",
    "\n",
    "# Set Arial as the default font\n",
    "custom_rc = {\n",
    "    'font.family': 'Arial',  # Set the desired font for this plot\n",
    "}\n",
    "\n",
    "color_bys = [state_key]\n",
    "#basis_types = ['', 'PAGA', 'KNN', 'PCA', 'UMAP']\n",
    "basis_types = ['UMAP']\n",
    "font_size=8\n",
    "point_size=4\n",
    "alpha=0.8\n",
    "figsize=(0.9*len(combined_keys),1)\n",
    "ncols = len(combined_keys)\n",
    "nrows = 1\n",
    "pal = {'state':'tab10'}\n",
    "k=15\n",
    "edges_color='grey'\n",
    "edges_width=0.05\n",
    "layout='kk'\n",
    "threshold = 0.1\n",
    "node_size_scale=0.1\n",
    "edge_width_scale=0.1\n",
    "\n",
    "with plt.rc_context(rc=custom_rc):\n",
    "    ccd.pl.plot_all_embeddings(\n",
    "        adata,\n",
    "        combined_keys,\n",
    "        color_bys=color_bys,\n",
    "        basis_types=basis_types,\n",
    "        pal=pal,\n",
    "        k=k,\n",
    "        edges_color=edges_color,\n",
    "        edges_width=edges_width,\n",
    "        layout=layout,\n",
    "        threshold=threshold,\n",
    "        node_size_scale=node_size_scale,\n",
    "        edge_width_scale=edge_width_scale,\n",
    "        font_size=font_size,\n",
    "        point_size=point_size,\n",
    "        alpha=alpha,\n",
    "        figsize=figsize,\n",
    "        ncols=ncols,\n",
    "        seed=1,\n",
    "        leiden_key='leiden',\n",
    "        save_dir=save_dir,\n",
    "        file_suffix=file_suffix,\n",
    "        save_format='svg'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and smooth the signal along the path\n",
    "batch_id=adata.obs['batch'].unique()[0]\n",
    "batch_indices = np.where(adata.obs['batch'] == batch_id)[0]\n",
    "_, _, _, feature_order = ccd.ul.sort_and_smooth_signal_along_path(adata, signal_key='Concord', path=batch_indices, sigma=2)\n",
    "adata.obsm['Concord_sorted'] = adata.obsm['Concord'][:, feature_order]\n",
    "\n",
    "_, _, _, feature_order = ccd.ul.sort_and_smooth_signal_along_path(adata, signal_key='Concord-decoder', path=batch_indices, sigma=2)\n",
    "adata.obsm['Concord-decoder_sorted'] = adata.obsm['Concord-decoder'][:, feature_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of original data and Concord latent\n",
    "import matplotlib.pyplot as plt\n",
    "figsize = (2.3, 1.8)\n",
    "ncols = 5\n",
    "title_fontsize = 9\n",
    "dpi = 600\n",
    "fig, axes = plt.subplots(1, ncols, figsize=(figsize[0] * ncols, figsize[1]), dpi=dpi)\n",
    "ccd.pl.heatmap_with_annotations(adata, val='no_noise', obs_keys=[state_key], ax = axes[0], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\n",
    "ccd.pl.heatmap_with_annotations(adata, val='wt_noise', obs_keys=[state_key], ax = axes[1], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State+noise', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\n",
    "ccd.pl.heatmap_with_annotations(adata, val='X', obs_keys=[state_key, batch_key], ax = axes[2], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='State+noise+batch', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\n",
    "ccd.pl.heatmap_with_annotations(adata, val='Concord_sorted', obs_keys=[state_key, batch_key], ax = axes[3], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Concord latent', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\n",
    "ccd.pl.heatmap_with_annotations(adata, val='Concord-decoder_sorted', obs_keys=[state_key, batch_key], ax = axes[4], use_clustermap=False, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Concord-decoder latent', save_path=None, figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)\n",
    "plt.tight_layout(w_pad=0.0, h_pad=0.1)\n",
    "plt.savefig(save_dir / f\"all_heatmaps_{file_suffix}.svg\", dpi=dpi, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd.pl.heatmap_with_annotations(adata, val='Concord_sorted', obs_keys=[state_key, batch_key], ax = axes[3], use_clustermap=True, yticklabels=False, cluster_cols=False, cluster_rows=False, value_annot=False, cmap='viridis', title='Concord latent', save_path=f\"heatmap_wt_annot_{file_suffix}.svg\", figsize=figsize, dpi=dpi, title_fontsize=title_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(data_dir / f\"adata_{file_suffix}.h5ad\")\n",
    "adata_state.write_h5ad(data_dir / f\"adata_state_{file_suffix}.h5ad\")\n",
    "file_suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(data_dir / f\"adata_Feb06-1037.h5ad\")\n",
    "adata_state = sc.read(data_dir / f\"adata_state_Feb06-1037.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run topological analysis pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_methods = [\"PCA\", \"UMAP\", \"t-SNE\", \"DiffusionMap\", \"NMF\", \n",
    "             \"FactorAnalysis\", \"FastICA\", \"LDA\", \"ZIFA\", \"scVI\", \"PHATE\", \n",
    "             \"Concord\", \"Concord-decoder\"]\n",
    "# exclude [\"UMAP\", \"t-SNE\"] from run_method, and save as combined_keys\n",
    "exclude_keys = [\"PCA\", \"UMAP\", \"t-SNE\"]\n",
    "combined_keys_topo = ['no_noise_PCA', 'wt_noise_PCA'] + [key for key in run_methods if key not in exclude_keys]\n",
    "combined_keys_topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homology_dimensions = [0,1,2]\n",
    "diagrams = {}\n",
    "for key in combined_keys_topo:\n",
    "    print(f\"Computing persistent homology for {key}\")\n",
    "    diagrams[key] =  ccd.ul.compute_persistent_homology(adata, key=key, homology_dimensions=homology_dimensions)\n",
    "\n",
    "import pickle\n",
    "with open(save_dir / f\"topology_diagrams_{file_suffix}.pkl\", 'wb') as f:\n",
    "    pickle.dump(diagrams, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir / f\"topology_diagrams_{file_suffix}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(Path('../save/dev_simulation_clustereasy_singlebatch-Feb06/topology_diagrams_Feb06-1037.pkl'), 'rb') as f:\n",
    "    diagrams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_betti_numbers = [2,0,0]\n",
    "max_betti = np.max(expected_betti_numbers)\n",
    "topology_results = ccd.ul.benchmark_topology(diagrams, expected_betti_numbers=expected_betti_numbers, save_dir=save_dir, file_suffix=file_suffix)\n",
    "topology_metrics = topology_results['combined_metrics']#.drop(index=['no_noise_PCA', 'wt_noise_PCA'])\n",
    "topology_metrics[('Betti number', 'L1 distance')] = topology_metrics[('Betti number', 'L1 distance')].clip(upper=2 * max_betti)\n",
    "topology_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology_df = topology_metrics.copy()\n",
    "\n",
    "# Rename row name \"no_noise_PCA\" to \"no_noise\", \"wt_noise_PCA\" to \"wt_noise\"\n",
    "topology_df.rename(\n",
    "    index={\n",
    "        \"no_noise_PCA\": \"no_noise\",\n",
    "        \"wt_noise_PCA\": \"wt_noise\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "topology_df[(\"Topological metrics\", \"Betti curve stability\")] = topology_df[\"Betti curve\"][\n",
    "    [\"Entropy\"]\n",
    "]\n",
    "topology_df[(\"Topological metrics\", \"Betti number accuracy\")] = topology_df[\"Betti number\"][\n",
    "    [\"L1 distance\"]\n",
    "]\n",
    "\n",
    "topology_df.drop(\n",
    "    columns=[\n",
    "        (\"Betti curve\", \"Variance\"),\n",
    "        (\"Betti curve\", \"Entropy\"),\n",
    "        (\"Betti number\", \"L1 distance\")\n",
    "    ],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "topology_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_name1 = ''\n",
    "agg_name2 = 'Topology Score'\n",
    "drop_methods = ['Concord-decoder', 'Concord-pknn0']\n",
    "topology_scores = ccd.ul.benchmark_stats_to_score(topology_df.drop(index=drop_methods), min_max_scale=True, one_minus=True, aggregate_score=False, aggregate_score_name1=None, aggregate_score_name2=None, rank=False, rank_col=None, name_exact=False)\n",
    "# Weight the metrics\n",
    "topology_scores[(\"\", \"Topology Score\")] = topology_scores[(\"Topological metrics\", \"Betti curve stability\")]*0.2 + topology_scores[(\"Topological metrics\", \"Betti number accuracy\")]*0.8\n",
    "topology_scores.sort_values(by=(\"\", \"Topology Score\"), ascending=False, inplace=True)\n",
    "topology_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(rc=custom_rc):\n",
    "    ccd.pl.plot_benchmark_table(topology_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', agg_name = agg_name1, save_path=save_dir / f\"topology_results_{file_suffix}.pdf\", figsize=(6, 8), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder diagrams with the same order as the combined keys\n",
    "diagrams_ordered = {key: diagrams[key] for key in combined_keys_topo}\n",
    "# Change the key names to remove 'PCA_'\n",
    "diagrams_ordered = {key.replace('_PCA', ''): diagrams_ordered[key] for key in diagrams_ordered}\n",
    "ccd.pl.plot_persistence_diagrams(diagrams_ordered, base_size=(1.3, 1.5), dpi=300, marker_size=4, n_cols=12, fontsize=10, save_path=save_dir / f\"persistence_diagrams_{file_suffix}.svg\", legend=False, label_axes=False, axis_ticks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd.pl.plot_betti_curves(diagrams_ordered, nbins=100, base_size=(1.3, 1.5), n_cols=12, fontsize=10, save_path=save_dir / f\"betti_curves_{file_suffix}.pdf\", dpi=300, legend=False, label_axes=False, axis_ticks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geomtric Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated benchmark pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_metrics = ['cell_distance_corr', 'local_distal_corr', 'trustworthiness', 'state_distance_corr', 'state_dispersion_corr']\n",
    "dist_metric = 'cosine'\n",
    "corr_types = ['pearsonr', 'spearmanr', 'kendalltau']\n",
    "#groundtruth_key = 'wt_noise'\n",
    "groundtruth_key = 'no_noise'\n",
    "# Convert state_dispersion to a dict of groundtruth dispersion\n",
    "#groundtruth_dispersion = {'cluster_' + str(i): state_dispersion[i]**2 for i in range(5)} # convert to variance\n",
    "geometry_df, geometry_full = ccd.ul.benchmark_geometry(adata, keys=combined_keys, eval_metrics=geometry_metrics, \n",
    "                                      dist_metric=dist_metric,\n",
    "                                      corr_types = corr_types,\n",
    "                                      groundtruth_key = groundtruth_key,\n",
    "                                      ground_truth_dispersion_key = 'wt_noise',\n",
    "                                      #groundtruth_dispersion = groundtruth_dispersion,\n",
    "                                      state_key = state_key,\n",
    "                                      batch_key = batch_key,\n",
    "                                      dispersion_metric='var',\n",
    "                                      return_type='full',\n",
    "                                      start_point=0,\n",
    "                                      end_point=adata.n_obs-1,\n",
    "                                      pseudotime_k = 30,\n",
    "                                      truetime_key = 'time',\n",
    "                                      save_dir=save_dir, \n",
    "                                      file_suffix=file_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_full['state_dispersion_corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the dataframe by computing average for each metric\n",
    "geometry_df = ccd.ul.simplify_geometry_benchmark_table(geometry_df)\n",
    "geometry_df = geometry_df.drop(columns=[('Geometric metrics', 'State distance correlation')]) # Redundant with cell distance correlation\n",
    "geometry_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_name1 = ''\n",
    "agg_name2 = 'Geometric Score'\n",
    "drop_methods = ['Concord-decoder', 'Concord-pknn0']\n",
    "geometry_scores = ccd.ul.benchmark_stats_to_score(\n",
    "    geometry_df.drop(index=drop_methods), fillna = 0,               \n",
    "    min_max_scale=False, one_minus=False, aggregate_score=True, aggregate_score_name1=agg_name1, aggregate_score_name2=agg_name2, rank=True, rank_col=(agg_name1,agg_name2))\n",
    "geometry_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(rc=custom_rc):\n",
    "    ccd.pl.plot_benchmark_table(geometry_scores, pal='PRGn', pal_agg='RdYlBu_r', cmap_method = 'minmax', agg_name = agg_name1, save_path=save_dir / f\"geometry_results_noscale_{dist_metric}_{groundtruth_key}_{file_suffix}.pdf\", figsize=(8.5, 7), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(rc=custom_rc):\n",
    "    ccd.pl.plot_distance_heatmap(geometry_full['cell_distance_corr']['distance'], n_cols = 12, figsize=(1.1,1.3), cbar=False, dpi=300, save_path=save_dir / f\"cell_distance_hmap_{file_suffix}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trustworthiness_scores = geometry_full['trustworthiness']['scores']\n",
    "drop_methods = ['Concord-pknn0', 'Concord-decoder']\n",
    "# Drop row with column 'Embedding' in drop_methods\n",
    "trustworthiness_scores = trustworthiness_scores[~trustworthiness_scores['Embedding'].isin(drop_methods)]\n",
    "with plt.rc_context(rc=custom_rc):\n",
    "    ccd.pl.plot_trustworthiness(trustworthiness_scores, text_shift=2, legend=False, save_path=save_dir / f\"trustworthiness_{groundtruth_key}_{file_suffix}.pdf\", figsize=(4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop value with keys in drop_methods from dictionary\n",
    "import matplotlib.pyplot as plt\n",
    "dispersion_dict = geometry_full['state_dispersion_corr']['dispersion']\n",
    "dispersion_dict = {key: dispersion_dict[key] for key in dispersion_dict if key not in drop_methods}\n",
    "correlation_df = geometry_full['state_dispersion_corr']['correlation'].drop(index=drop_methods)\n",
    "with plt.rc_context(rc=custom_rc):\n",
    "    ccd.pl.plot_geometry_scatter(\n",
    "        data_dict = dispersion_dict,\n",
    "        correlation= correlation_df,\n",
    "        s=30, c='darkblue',\n",
    "        ground_key = 'wt_noise',\n",
    "        linear_fit = True,\n",
    "        n_cols = 11, figsize=(1.5,1.75), dpi=300, save_path=save_dir / f\"state_dispersion_scatter_{groundtruth_key}_{file_suffix}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all metrics into one table\n",
    "import pandas as pd\n",
    "all_scores = pd.concat([topology_scores, geometry_scores], axis=1)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores[('Aggregate score', 'Topology')] = all_scores[('', 'Topology Score')]\n",
    "all_scores[('Aggregate score', 'Geometry')] = all_scores[('', 'Geometric Score')]\n",
    "all_scores[('Aggregate score', 'Average Score')] = all_scores[\"Aggregate score\"][[\"Topology\", \"Geometry\"]].mean(axis=1)\n",
    "# sort by average score\n",
    "all_scores.sort_values(by=[('Aggregate score', 'Average Score')], ascending=False, inplace=True)\n",
    "all_scores.drop(\n",
    "    columns=[\n",
    "        ('', 'Topology Score'),\n",
    "        ('', 'Geometric Score')\n",
    "    ],\n",
    "    inplace=True\n",
    ")\n",
    "# Save table\n",
    "all_scores.to_csv(save_dir / f\"benchmark_results_{file_suffix}.csv\")\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(rc=custom_rc):\n",
    "    ccd.pl.plot_benchmark_table(all_scores, pal='viridis', pal_agg='viridis', cmap_method = 'minmax', agg_name = 'Aggregate score', save_path=save_dir / f\"all_results_{file_suffix}.pdf\", figsize=(10, 6.2), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concord",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
